# ðŸ§  CNN for Image Classification using PyTorch (SVHN Dataset)

> A deep learning project where I built and trained a **Convolutional Neural Network (CNN)** from scratch using **PyTorch** to classify real-world images of house numbers from the **SVHN (Street View House Numbers)** dataset.

---

## ðŸ“˜ Overview

This project demonstrates how a simple CNN can perform **image classification** tasks effectively.  
The model is trained on the **SVHN dataset**, which contains images of digits (0â€“9) captured from real-world street scenes.

### ðŸŽ¯ Objective
Build, train, and evaluate a CNN using PyTorch to classify digits (0â€“9) from images in the SVHN dataset.

---

## ðŸ§© Dataset

- **Name:** SVHN (Street View House Numbers)
- **Source:** Google Street View
- **Image Size:** 32x32 pixels (RGB)
- **Classes:** 10 (digits 0â€“9)
- **Train Samples:** 73,257  
- **Test Samples:** 26,032  

---

## ðŸ—ï¸ Model Architecture

| Layer | Type | Details |
|--------|------|----------|
| 1 | Convolutional | 3Ã—3 kernel, 32 filters, padding=1 |
| 2 | ReLU Activation | Non-linear transformation |
| 3 | Convolutional | 3Ã—3 kernel, 64 filters, padding=1 |
| 4 | ReLU Activation | Non-linear transformation |
| 5 | MaxPooling | 2Ã—2, stride=2 (halves spatial size) |
| 6 | Fully Connected | 64Ã—16Ã—16 â†’ 10 output classes |

> **Padding** keeps the feature map size same after convolution.  
> **MaxPooling** reduces the spatial dimensions (32Ã—32 â†’ 16Ã—16) for efficient computation.

---

## âš™ï¸ Training Configuration

| Parameter | Value |
|------------|--------|
| **Optimizer** | Adam |
| **Loss Function** | CrossEntropyLoss |
| **Learning Rate** | 0.001 |
| **Batch Size** | 64 |
| **Epochs** | 10 |
| **Device** | NVIDIA T4 GPU (Google Colab) |

---

## ðŸ§  Results

| Metric | Score |
|--------|--------|
| **Training Accuracy** | ~82% |
| **Validation Accuracy** | ~73% |
| **Total Parameters** | â‰ˆ 700,000 |
| **Training Time** | ~8â€“10 minutes on Colab GPU |

---

## ðŸ“Š Visualizations

Below are the key output visualizations from the training and evaluation process.  
All screenshots are stored in the **`outputs/`** folder.

### ðŸ§® 1. Training Loss vs Epochs
![Training Loss](./outputs/1.png)

---

### ðŸ“ˆ 2. Training vs Validation Accuracy
![Accuracy](./outputs/2.png)

---

### ðŸŒ€ 3. Confusion Matrix
![Confusion Matrix](./outputs/3.png)

---

### ðŸ–¼ï¸ 4. Sample Predictions
![Sample Predictions](./outputs/4.png)

> *Each image was generated after training the CNN for 10 epochs on the SVHN dataset.*
----

## ðŸ’¬ Discussion

### ðŸ§© Padding and Stride Effects:
- **Padding (1):** Keeps the spatial size same after convolution.  
- **Stride (1):** Ensures all pixels contribute to feature extraction.  
- **MaxPooling (2Ã—2):** Reduces the size of feature maps from 32Ã—32 â†’ 16Ã—16.  

This balance helps the CNN extract both low-level details (edges, textures) and high-level features (digit shapes).

---

## ðŸ”® Future Work

Possible improvements:
- Add **Dropout layers** to reduce overfitting  
- Use **Data Augmentation** for better generalization  
- Try deeper models like **ResNet** or **VGG** for comparison  

---

## ðŸš€ How to Run This Project

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/your-username/SVHN-CNN-Classifier.git
cd SVHN-CNN-Classifier



## â–¶ï¸ Running on Google Colab

If you prefer running this project on **Google Colab**, follow these simple steps:

1ï¸âƒ£ **Upload the Notebook**  
   Upload the provided `CNN_SVHN.ipynb` file to your Google Colab workspace.

2ï¸âƒ£ **Enable GPU Support**  
   Go to the top menu â†’ `Runtime` â†’ `Change runtime type` â†’  
   Under *Hardware Accelerator*, select **GPU**, then click **Save**.

3ï¸âƒ£ **Run All Cells**  
   Execute all cells in order by selecting  
   `Runtime â†’ Run all`  
   or pressing **Ctrl + F9** to start training.

ðŸ’¡ *Note: The model will automatically download the SVHN dataset on the first run.*


## ðŸ§¾ Author

**ðŸ‘¤ Qasim Naveed**  
ðŸŽ“ Computer Science Student | ðŸ’» Deep Learning Enthusiast  
ðŸ”— [LinkedIn](https://www.linkedin.com) | ðŸŒ [Medium](https://medium.com)

---

## â­ Acknowledgements

- **Dataset:** [SVHN - Street View House Numbers](http://ufldl.stanford.edu/housenumbers/)  
- **Framework:** [PyTorch](https://pytorch.org/)  

> â€œThe best way to learn AI is to make it see the world â€” one pixel at a time.â€  
> â€” *Qasim Naveed*
